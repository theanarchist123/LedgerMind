# ================================
# LedgerMind Environment Variables
# ================================

# MongoDB Configuration
# Get your free MongoDB Atlas connection string from: https://www.mongodb.com/cloud/atlas
MONGODB_URI="mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority"
MONGODB_DB="ledgermind"
MONGODB_COLLECTION="ledger"

# Better Auth Configuration
# Generate a secure secret using: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
BETTER_AUTH_SECRET="your_32_character_random_secret_here"

# Application URL
# Update this when deploying to production
NEXT_PUBLIC_APP_URL="http://localhost:3000"

# OAuth Providers (Optional - for social login)
# Get credentials from:
# Google: https://console.cloud.google.com/apis/credentials
# GitHub: https://github.com/settings/developers
GOOGLE_CLIENT_ID="your-google-oauth-client-id"
GOOGLE_CLIENT_SECRET="your-google-oauth-client-secret"
GITHUB_CLIENT_ID="your-github-oauth-client-id"
GITHUB_CLIENT_SECRET="your-github-oauth-client-secret"

# AI/ML Configuration
# Choose your provider: "ollama" (recommended for cloud), "gemini", "groq", or "mock"
LLM_PROVIDER="ollama"
EMBEDDINGS_PROVIDER="ollama"

# Google Gemini AI (Optional - Alternative provider)
# Get your API key from: https://ai.google.dev/
GOOGLE_API_KEY="your_google_gemini_api_key_here"

# Groq API (Optional - Alternative fast inference)
# Get free API key from: https://console.groq.com
GROQ_API_KEY=""

# Ollama Cloud (Recommended - Production ready with cloud hosting)
# Get your API key from: https://ollama.com
OLLAMA_BASE_URL="https://ollama.com"
OLLAMA_API_KEY="your_ollama_cloud_api_key_here"
OLLAMA_LLM_MODEL="gemma3:4b-cloud"
OLLAMA_EMBED_MODEL="nomic-embed-text:latest"

# Ollama Local (Optional - For local AI processing)
# Install from: https://ollama.ai/
# OLLAMA_BASE_URL="http://localhost:11434"
# OLLAMA_LLM_MODEL="llama3.2"
# OLLAMA_EMBED_MODEL="nomic-embed-text"

# OCR Configuration
# Tesseract is used for receipt text extraction
# Leave empty to use built-in Tesseract.js (recommended for Vercel)
TESSERACT_PATH=""

# Optional: Heuristic-only mode (skip LLM for categorization)
USE_LOCAL_RECEIPT_PARSE="false"
